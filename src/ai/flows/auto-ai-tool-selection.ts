// AutoAIToolSelection flow
'use server';
/**
 * @fileOverview Automatically selects the best AI tool based on the complexity and context of the query.
 *
 * - autoAIToolSelection - A function that automatically selects an AI tool and returns its response.
 * - AutoAIToolSelectionInput - The input type for the autoAIToolSelection function.
 * - AutoAIToolSelectionOutput - The return type for the autoAIToolSelection function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const AutoAIToolSelectionInputSchema = z.object({
  query: z.string().describe('The user query to be processed by the AI tool.'),
  userId: z.string().describe('The ID of the user making the query.'),
});
export type AutoAIToolSelectionInput = z.infer<typeof AutoAIToolSelectionInputSchema>;

const AutoAIToolSelectionOutputSchema = z.object({
  tool: z.string().describe('The AI tool that was automatically selected.'),
  response: z.string().describe('The response generated by the selected AI tool.'),
  rawResponse: z.string().optional().describe('The raw response from the AI provider, for debugging.'),
});
export type AutoAIToolSelectionOutput = z.infer<typeof AutoAIToolSelectionOutputSchema>;

export async function autoAIToolSelection(input: AutoAIToolSelectionInput): Promise<AutoAIToolSelectionOutput> {
  return autoAIToolSelectionFlow(input);
}

const selectAITool = ai.defineTool({
  name: 'selectAITool',
  description: 'Selects the most appropriate AI tool based on the complexity and context of the user query, considering cost, latency and quality requirements.',
  inputSchema: z.object({
    query: z.string().describe('The user query to be processed.'),
  }),
  outputSchema: z.string().describe('The name of the selected AI tool (GPT, Gemini, Purplexcity, Grok, Deepseek, FreeTool).'),
}, async (input) => {
  // Implement the logic to select the AI tool based on the query.
  // This is a placeholder; replace with actual logic.
  // Consider using a separate LLM call to determine the best tool.
  // For now, let's just return 'Gemini' as the default tool.
  return 'Gemini';
});

const generateResponse = ai.defineTool({
  name: 'generateResponse',
  description: 'Generates a response to the user query using the specified AI tool.',
  inputSchema: z.object({
    query: z.string().describe('The user query.'),
    tool: z.string().describe('The AI tool to use for generating the response.'),
    userId: z.string().describe('The ID of the user making the query.'),
  }),
  outputSchema: z.object({
    response: z.string().describe('The response generated by the AI tool.'),
    rawResponse: z.string().optional().describe('The raw response from the AI provider, for debugging.'),
  }),
}, async (input) => {
  // This is a placeholder; replace with actual logic to call the appropriate AI tool.
  // You'll likely need to use a switch statement or a map to route the request to the correct tool.
  // For now, let's just return a dummy response.
  console.log(`Calling backend AI_BACKEND_URL + "/api/ai" with tool ${input.tool}`);

  const backendResponse = await fetch(process.env.AI_BACKEND_URL + "/api/ai", {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      tool: input.tool,
      input: input.query,
      userId: input.userId,
    }),
  });

  if (!backendResponse.ok) {
    throw new Error(`HTTP error! status: ${backendResponse.status}`);
  }

  const data = await backendResponse.json();

  return {
    response: data.provider_parsed,
    rawResponse: data.provider_raw,
  };
});

const autoAIToolSelectionFlow = ai.defineFlow({
  name: 'autoAIToolSelectionFlow',
  inputSchema: AutoAIToolSelectionInputSchema,
  outputSchema: AutoAIToolSelectionOutputSchema,
  tools: [selectAITool, generateResponse],
}, async (input) => {
  const selectedTool = await selectAITool({ query: input.query });
  const {response, rawResponse} = await generateResponse({ query: input.query, tool: selectedTool, userId: input.userId });

  return {
    tool: selectedTool,
    response: response,
    rawResponse: rawResponse,
  };
});
